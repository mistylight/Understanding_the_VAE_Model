{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q pytorch_lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9913344it [00:10, 990779.78it/s]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29696it [00:00, 3930761.88it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 122880/1648877 [00:00<00:01, 1226823.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1649664it [00:02, 670023.14it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5120it [00:00, 12866888.24it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/zpzhou/opt/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1614389903258/work/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | encoder         | Sequential | 38.2 K\n",
      "1 | encoder_mu      | Sequential | 110   \n",
      "2 | encoder_log_var | Sequential | 110   \n",
      "3 | decoder         | Sequential | 29.2 K\n",
      "-----------------------------------------------\n",
      "67.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "67.6 K    Total params\n",
      "0.270     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zpzhou/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/1876 [00:00<02:08, 14.63it/s, loss=669, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zpzhou/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1876/1876 [00:56<00:00, 33.05it/s, loss=135, v_num=0]\n",
      "best checkpoint: lightning_logs/version_0/checkpoints/vae-epoch=epoch=19.ckpt\n",
      "Testing:   4%|▍         | 13/313 [00:00<00:02, 128.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zpzhou/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 313/313 [00:02<00:00, 127.33it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test/kldiv_loss': 8.309773445129395,\n",
      " 'test/loss': 132.6034393310547,\n",
      " 'test/recon_loss': 124.29364776611328}\n",
      "--------------------------------------------------------------------------------\n",
      "[{'test/loss': 132.6034393310547, 'test/recon_loss': 124.29364776611328, 'test/kldiv_loss': 8.309773445129395}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from types import SimpleNamespace \n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import random_split\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Basic NN modules, enhanced with bn/relu. \n",
    "# ------------------------------------------------------------------------------\n",
    "class Conv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bn=False, relu=False):\n",
    "        super(Conv2d, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding, stride=stride)\n",
    "        self.relu = nn.LeakyReLU() if relu else None\n",
    "        self.bn = nn.BatchNorm2d(out_channels) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        # https://stackoverflow.com/questions/39691902/ordering-of-batch-normalization-and-dropout\n",
    "        if self.bn is not None: x = self.bn(x)\n",
    "        if self.relu is not None: x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class Deconv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bn=False, relu=False):\n",
    "        super(Deconv2d, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.deconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, padding=padding, stride=stride, output_padding=output_padding)\n",
    "        self.relu = nn.LeakyReLU() if relu else None\n",
    "        self.bn = nn.BatchNorm2d(out_channels) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.deconv(x)\n",
    "        if self.bn is not None: x = self.bn(x)\n",
    "        if self.relu is not None: x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bn=False, relu=False):\n",
    "        super(Linear, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.fc = nn.Linear(in_channels, out_channels)\n",
    "        self.relu = nn.LeakyReLU() if relu else None\n",
    "        self.bn = nn.BatchNorm1d(out_channels) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        if self.bn is not None: x = self.bn(x)\n",
    "        if self.relu is not None: x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class View(nn.Module):\n",
    "    def __init__(self, *shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# The main VAE model.\n",
    "# ------------------------------------------------------------------------------\n",
    "class LitVAE(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.hidden_size = args.hidden_size\n",
    "        # --------------------------- encoder ---------------------------\n",
    "        # input: (N, 1, H, W) single-channel images with values in (0, 1)\n",
    "        # output: (hidden_size) mu, log(sigma^2) for Q(z|X)\n",
    "        # ---------------------------------------------------------------\n",
    "        # encoder backbone \n",
    "        self.encoder = nn.Sequential(\n",
    "            Conv2d(1, 8, 3, padding=1, stride=2, bn=True, relu=True),\n",
    "            Conv2d(8, 8, 3, padding=1, stride=1, bn=True, relu=True),\n",
    "            \n",
    "            Conv2d(8, 16, 3, padding=1, stride=2, bn=True, relu=True),\n",
    "            Conv2d(16, 16, 3, padding=1, stride=1, bn=True, relu=True),\n",
    "            \n",
    "            Conv2d(16, 32, 3, padding=1, stride=2, bn=True, relu=True),\n",
    "            Conv2d(32, 32, 3, padding=1, stride=1, bn=True, relu=True),\n",
    "            \n",
    "            Conv2d(32, 32, 3, padding=1, stride=2, bn=True, relu=True),\n",
    "            Conv2d(32, 32, 3, padding=1, stride=1, bn=True, relu=True),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            Linear(32 * 2 * 2, self.hidden_size, bn=True, relu=True),\n",
    "        )\n",
    "        # encoder head for mu\n",
    "        self.encoder_mu = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "        )\n",
    "        # encoder head for log(var)\n",
    "        self.encoder_log_var = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "        )\n",
    "        # --------------------------- decoder ---------------------------\n",
    "        # input: (hidden_size) z sampled from Q(z|X)\n",
    "        # output: (N, 1, H, W) reconstructed images,\n",
    "        #         unnormalized logits, apply sigmoid to get final output\n",
    "        # ---------------------------------------------------------------\n",
    "        self.decoder = nn.Sequential(\n",
    "            Linear(self.hidden_size, 32 * 2 * 2, bn=True, relu=True),\n",
    "            View(-1, 32, 2, 2),\n",
    "\n",
    "            Deconv2d(32, 32, 3, padding=1, stride=2, output_padding=1, bn=True, relu=True),\n",
    "            Conv2d(32, 32, 3, padding=1, stride=1, bn=True, relu=True),\n",
    "            \n",
    "            Deconv2d(32, 16, 3, padding=1, stride=2, output_padding=0, bn=True, relu=True),\n",
    "            Conv2d(16, 16, 3, padding=1, stride=1, bn=True, relu=True),\n",
    "            \n",
    "            Deconv2d(16, 8, 3, padding=1, stride=2, output_padding=1, bn=True, relu=True),\n",
    "            Conv2d(8, 8, 3, padding=1, stride=1, bn=True, relu=True),\n",
    "            \n",
    "            Deconv2d(8, 1, 3, padding=1, stride=2, output_padding=1, bn=True, relu=True),\n",
    "            Conv2d(1, 1, 3, padding=1, stride=1, bn=False, relu=False),\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x_feats = self.encoder(x)\n",
    "        z_mu = self.encoder_mu(x_feats)\n",
    "        z_log_var = self.encoder_log_var(x_feats)\n",
    "        z_normal = torch.randn(x.size(0), self.hidden_size).to(self.device)\n",
    "        z = torch.exp(z_log_var * 0.5) * z_normal + z_mu\n",
    "        return z, z_mu, z_log_var\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, z_mu, z_log_var = self.encode(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat, z, z_mu, z_log_var\n",
    "\n",
    "    def criterion(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x_hat, z, z_mu, z_log_var = self.forward(x)\n",
    "        recon_loss = F.binary_cross_entropy_with_logits(x_hat, x, reduction=\"sum\")\n",
    "        kldiv_loss = (0.5 * (-(z_log_var + 1) + z_log_var.exp() + z_mu.pow(2))).sum()\n",
    "        recon_loss /= x.size(0); kldiv_loss /= x.size(0)\n",
    "        loss = recon_loss + kldiv_loss\n",
    "        return {\"loss\": loss, \"recon_loss\": recon_loss, \"kldiv_loss\": kldiv_loss}\n",
    "\n",
    "    def log_scalar(self, split, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            self.log(f\"{split}/{key}\", value, on_epoch=True)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        metrics = self.criterion(batch, batch_idx)\n",
    "        self.log_scalar(\"train\", **metrics)\n",
    "        return metrics[\"loss\"]\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        metrics = self.criterion(batch, batch_idx)\n",
    "        self.log_scalar(\"val\", **metrics)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        metrics = self.criterion(batch, batch_idx)\n",
    "        self.log_scalar(\"test\", **metrics)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "def main():\n",
    "    pl.seed_everything(1234)\n",
    "\n",
    "    # replace with argparser when running from CLI\n",
    "    args = SimpleNamespace(\n",
    "        batch_size=32,\n",
    "        max_epochs=20,\n",
    "        hidden_size=10,\n",
    "        gpus=0,     # set to > 0 to enable cuda\n",
    "    )\n",
    "    \n",
    "    dataset = MNIST('', train=True, download=True, transform=transforms.ToTensor())\n",
    "    mnist_test = MNIST('', train=False, download=True, transform=transforms.ToTensor())\n",
    "    mnist_train, mnist_val = random_split(dataset, [55000, 5000])\n",
    "\n",
    "    train_loader = DataLoader(mnist_train, batch_size=args.batch_size)\n",
    "    val_loader = DataLoader(mnist_val, batch_size=args.batch_size)\n",
    "    test_loader = DataLoader(mnist_test, batch_size=args.batch_size)\n",
    "\n",
    "    model = LitVAE(args)\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val/loss',\n",
    "        filename='vae-epoch={epoch:02d}',\n",
    "        mode='min',\n",
    "    )\n",
    "    trainer = pl.Trainer.from_argparse_args(args)\n",
    "    trainer.callbacks += [checkpoint_callback]\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    print('best checkpoint:', os.path.relpath(checkpoint_callback.best_model_path))\n",
    "\n",
    "    result = trainer.test(test_dataloaders=test_loader)\n",
    "    print(result)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b98ce01d6443f9ed8de6b2298de45a5462ef793670bc2920aea9ee85010384a1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
